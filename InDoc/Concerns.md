# 1.24
Concern1:
    According to [1], VGG-16 and VGG-19 are two outliers among all the networks, which means these two models use much more computation and memory than others. To support our results, perhaps we need to do specialization on other architectures. 

Concern2:
    In cs231n_2017 Lecture 9 - 33 [2], the authors distinguish memory usage from number of parameters. But in our paper, we treat number of parameters as the only representation of memory usage. Why is there the difference?

Concern3:
    About the model description section in my paper, whether these ideas are enough for a paper and whether they are innovative enough?
    
[1] An analysis of deep neural network models for practical applications, *Canziani, Alfredo and Paszke, Adam and Culurciello, Eugenio*

[2] Stanford cs231n_2017 Lecture 9 - 33, *Fei-Fei Li & Justin Johnson & Serena Yeung*
